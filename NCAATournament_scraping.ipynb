{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCAA tournament data - webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports for webscraping\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "#for saving and load data files\n",
    "import pickle\n",
    "import urllib3\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### loading bar\n",
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )\n",
    "        \n",
    "#MIT License\n",
    "#Copyright (c) 2016 bureaucratic-labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseURL = 'https://www.sports-reference.com'\n",
    "notAdded = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get tournament teams by year\n",
    "#tourneyTeamYear -- dictionary with year as key and value is list of teams in the tourney that year\n",
    "def getTourneyTeamYear(yearRange):\n",
    "    print(\"getting tournament teams by year\")\n",
    "    tourneyTeamYear = {}\n",
    "    \n",
    "    for i in range(yearRange[0],yearRange[1]+1):\n",
    "    \n",
    "        year = str(i)\n",
    "        print(year, end=\" \")\n",
    "        \n",
    "        tourneyTeamYear[year] = {}\n",
    "    \n",
    "        url =baseURL+'/cbb/postseason/'+year+'-ncaa.html'\n",
    "        html = urlopen(url)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for tround in soup.findAll('div', attrs={'class':'round'}):\n",
    "            for game in tround.findAll('div',recursive=False):\n",
    "                gameDetails = game.findAll('a')\n",
    "                if len(gameDetails) > 3:\n",
    "                    schools = [gameDetails[0].text.strip(),gameDetails[2].text.strip()]\n",
    "                    urls = [gameDetails[0][\"href\"],gameDetails[2][\"href\"]]\n",
    "                    if schools[0] not in tourneyTeamYear[year]:\n",
    "                        tourneyTeamYear[year][schools[0]] = urls[0]\n",
    "                    if schools[1] not in tourneyTeamYear[year]:\n",
    "                        tourneyTeamYear[year][schools[1]] = urls[1]\n",
    "\n",
    "        print(\"done\")        \n",
    "        \n",
    "    print(\"done\")\n",
    "    return tourneyTeamYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get teams played by tournament teams by year\n",
    "#allTeamYear\n",
    "def getAllTeamYear(yearRange,tourneyTeamYear):\n",
    "    print(\"getting teams played by tournament teams by year\")\n",
    "    allTeamYear = {}\n",
    "    \n",
    "    for i in range(yearRange[0],yearRange[1]+1):\n",
    "    \n",
    "        year = str(i)\n",
    "        print(year, end=\" \")\n",
    "    \n",
    "        allTeamYear[year] = {}\n",
    "    \n",
    "        for key, value in log_progress(tourneyTeamYear[year].items(),every=1):\n",
    "            if(key not in allTeamYear[year]):\n",
    "                allTeamYear[year][key] = value\n",
    "            teamURL =baseURL+value\n",
    "            teamhtml = urlopen(teamURL)\n",
    "            teamsoup = BeautifulSoup(teamhtml, 'html.parser')\n",
    "            gameSchedule = teamsoup.find('div', attrs={'id':'inner_nav'}).findAll('li')\n",
    "            gameScheduleLink = gameSchedule[2].find('a')\n",
    "            gameScheduleLink = gameScheduleLink[\"href\"]\n",
    "            \n",
    "            gameScheduleURL =baseURL+gameScheduleLink\n",
    "            gameSchedulehtml = urlopen(gameScheduleURL)\n",
    "            gameSchedulesoup = BeautifulSoup(gameSchedulehtml, 'html.parser')\n",
    "            tableRows = gameSchedulesoup.find('table', attrs={'id':'schedule'}).find('tbody').findAll('tr')\n",
    "            for row in tableRows:\n",
    "                team = row.findAll('td')\n",
    "                if year not in ['2015','2016','2017']:\n",
    "                    if team == None or len(team) < 4:\n",
    "                        continue\n",
    "                    team = team[3].find('a')\n",
    "                    if(team == None):\n",
    "                        continue\n",
    "                    teamName = team.text.strip()\n",
    "                    teamLink = team[\"href\"]\n",
    "                    if(teamName not in allTeamYear[year]):\n",
    "                        allTeamYear[year][teamName] = teamLink\n",
    "                else:\n",
    "                    if team == None or len(team) < 6:\n",
    "                        continue\n",
    "                    team = team[5].find('a')\n",
    "                    if(team == None):\n",
    "                        continue\n",
    "                    teamName = team.text.strip()\n",
    "                    teamLink = team[\"href\"]\n",
    "                    if(teamName not in allTeamYear[year]):\n",
    "                        allTeamYear[year][teamName] = teamLink\n",
    "        \n",
    "    print('done')\n",
    "    return allTeamYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get team stats for all teams (tournament team + the teams they played)\n",
    "#teamYearData --  dictionary with year as key and value is a dictionary with team as key and value in the form of [[team stats],[opponent stats]] \n",
    "#team/oppenent stats: [0G, 1MP, 2FG, 3FGA, 4FG%, 52P, 62PA, 72P%, 83P, 93PA, 103P%, 11FT, 12FTA, 13FT%, 14ORB, 15DRB, 16TRB, 17AST, 18STL, 19BLK, 20TOV, 21PF, 22PTS, 23PTS/G]\n",
    "#example: '2000': {'Duke': [[34, '', 1045, 2172, 0.481, 761, 1430, 0.532, 284, 742, 0.383, 618, 833, 0.742, 453, 860, 1313, 584, 333, 191, 480, 552, 2992, 88.0], [34, '', 934, 2238, 0.417, 737, 1686, 0.437, 197, 552, 0.357, 360, 537, 0.67, 526, 757, 1283, 472, 240, 123, 607, 690, 2425, 71.3]]}\n",
    "\n",
    "def getTeamYearData(yearRange,allTeamYear):\n",
    "    print(\"getting team stats for all teams (tournament team and the teams they played)\")\n",
    "    teamYearData = {}\n",
    "\n",
    "    for i in range(yearRange[0],yearRange[1]+1):\n",
    "    \n",
    "        year = str(i)\n",
    "        print(year, end=\" \")\n",
    "    \n",
    "        teamYearData[year] = {}\n",
    "    \n",
    "    \n",
    "        for key, value in log_progress(allTeamYear[year].items(),every=1):\n",
    "            if(key in teamYearData[year]):\n",
    "                continue\n",
    "            teamURL =baseURL+value\n",
    "            teamhtml = urlopen(teamURL)\n",
    "            teamsoup = BeautifulSoup(teamhtml, 'html.parser')\n",
    "            if(teamsoup.find('table', attrs={'id':'team_stats'})==None):\n",
    "                notAdded.append((key,year))\n",
    "                continue\n",
    "            table = teamsoup.find('table', attrs={'id':'team_stats'}).find('tbody')\n",
    "            teamStats = []\n",
    "            for row in table.findAll('tr'):\n",
    "                temp = []\n",
    "                if row.has_attr(\"class\"):\n",
    "                    continue\n",
    "                for stat in row.findAll('td'):\n",
    "                    temp.append(stat.text.strip())\n",
    "                teamStats.append(temp)\n",
    "            teamYearData[year][key] = teamStats\n",
    "                  \n",
    "    print('done')\n",
    "    \n",
    "    \n",
    "    #reformat teamYearData\n",
    "    #empty value represented with ''\n",
    "    print('reformatting data...')\n",
    "\n",
    "    for i in range(yearRange[0],yearRange[1]+1):\n",
    "        year = str(i)\n",
    "        for team in teamYearData[year]:\n",
    "            newStats = []\n",
    "            for stats in teamYearData[year][team]:\n",
    "                index = 0\n",
    "                newStat = []\n",
    "                for stat in stats:\n",
    "                    if stat != '':\n",
    "                        if index in [4,7,10,13,23]:\n",
    "                            newStat.append(float(stat))\n",
    "                        else:\n",
    "                            newStat.append(int(stat)) \n",
    "                    else:\n",
    "                        newStat.append('')\n",
    "                    index +=1\n",
    "                newStats.append(newStat)\n",
    "            teamYearData[year][team] = newStats\n",
    "    \n",
    "    print('done')\n",
    "    return teamYearData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get game data for all games played by tournament teams\n",
    "#dictionary with year as key and value is a list of lists containing [team1,team2,overall score]\n",
    "#example: '2000': [['Duke', 'Lamar', 137], ['Kansas', 'DePaul', 158]]\n",
    "\n",
    "def getGameYearData(yearRange,tourneyTeamYear):\n",
    "    print(\"getting game data for all games played by tournament teams\")\n",
    "    gameYearDataWithDuplicates = {}\n",
    "    gameYearData = {}\n",
    "\n",
    "    for i in range(yearRange[0],yearRange[1]+1):\n",
    "    \n",
    "        year = str(i)\n",
    "        print(year, end=\" \")\n",
    "    \n",
    "        gameYearDataWithDuplicates[year] = []\n",
    "    \n",
    "        for key, value in log_progress(tourneyTeamYear[year].items(),every=1):\n",
    "            teamURL = baseURL+value\n",
    "            teamhtml = urlopen(teamURL)\n",
    "            teamsoup = BeautifulSoup(teamhtml, 'html.parser')\n",
    "            gameSchedule = teamsoup.find('div', attrs={'id':'inner_nav'}).findAll('li')\n",
    "            gameScheduleLink = gameSchedule[2].find('a')\n",
    "            gameScheduleLink = gameScheduleLink[\"href\"]\n",
    "            \n",
    "            gameScheduleURL =baseURL+gameScheduleLink\n",
    "            gameSchedulehtml = urlopen(gameScheduleURL)\n",
    "            gameSchedulesoup = BeautifulSoup(gameSchedulehtml, 'html.parser')\n",
    "            tableRows = gameSchedulesoup.find('table', attrs={'id':'schedule'}).find('tbody').findAll('tr')\n",
    "            for row in tableRows:\n",
    "                team = row.findAll('td')\n",
    "                if year not in ['2015','2016','2017']:\n",
    "                    if team == None or len(team) < 8:\n",
    "                        continue\n",
    "                    opponent = team[3].find('a')\n",
    "                    if(opponent == None):\n",
    "                        continue\n",
    "                    opponentTeamName = opponent.text.strip()\n",
    "            \n",
    "                    score1 = team[6].text.strip()\n",
    "                    score2 = team[7].text.strip()\n",
    "            \n",
    "                    game = [key,opponentTeamName,int(score1)+int(score2)]\n",
    "                    gameYearDataWithDuplicates[year].append(game)\n",
    "                else:\n",
    "                    if team == None or len(team) < 10:\n",
    "                        continue\n",
    "                    opponent = team[5].find('a')\n",
    "                    if(opponent == None):\n",
    "                        continue\n",
    "                    opponentTeamName = opponent.text.strip()\n",
    "            \n",
    "                    score1 = team[8].text.strip()\n",
    "                    score2 = team[9].text.strip()\n",
    "            \n",
    "                    game = [key,opponentTeamName,int(score1)+int(score2)]\n",
    "                    gameYearDataWithDuplicates[year].append(game)\n",
    "        \n",
    "        \n",
    "    print('done')\n",
    "\n",
    "    print('deleting duplicate games...')\n",
    "    #delete duplicates from gameYearData \n",
    "    for i in range(yearRange[0],yearRange[1]+1):\n",
    "    \n",
    "        year = str(i)\n",
    "    \n",
    "        gameYearData[year] = []\n",
    "    \n",
    "        for game in gameYearDataWithDuplicates[year]:\n",
    "            duplicate = False\n",
    "            for gameCompare in gameYearData[year]:\n",
    "                if game[2] == gameCompare[2]:\n",
    "                    if (game[0]==gameCompare[0] and game[1]==gameCompare[1]) or (game[1]==gameCompare[0] and game[0]==gameCompare[1]):\n",
    "                        duplicate = True\n",
    "            if not duplicate:\n",
    "                gameYearData[year].append(game)\n",
    "\n",
    "    print('done')\n",
    "    return gameYearData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get game data for all games played in the tournament\n",
    "#dictionary with year as key and value is a list of lists containing [team1,team2,overall score] for everygame in the tournament\n",
    "#example: '2000': [['Duke', 'Lamar', 137], ['Kansas', 'DePaul', 158]]\n",
    "\n",
    "def getTournamentGameData(yearRange):\n",
    "\n",
    "    tournamentGameData = {}\n",
    "    \n",
    "    for i in range(yearRange[0],yearRange[1]+1):\n",
    "        year = str(i)\n",
    "        print(year, end =\" \")\n",
    "    \n",
    "        tournamentGameData[year] = []\n",
    "    \n",
    "        url =baseURL+'/cbb/postseason/'+year+'-ncaa.html'\n",
    "        html = urlopen(url)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        numSchoolsAdded = 1\n",
    "        for tround in soup.findAll('div', attrs={'class':'round'}):\n",
    "            for game in tround.findAll('div',recursive=False):\n",
    "                gameDetails = game.findAll('a')\n",
    "                if len(gameDetails) > 3:\n",
    "                    schools = [gameDetails[0].text.strip(),gameDetails[2].text.strip()]\n",
    "                    gameData = [schools[0],schools[1],int(gameDetails[1].text.strip())+int(gameDetails[3].text.strip())]\n",
    "                    tournamentGameData[year].append(gameData)\n",
    "        print(\"done\")\n",
    "        \n",
    "    print(\"done\")            \n",
    "    return tournamentGameData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gather all team ID's from ESPN.com\n",
    "\n",
    "def gather_teamIds():\n",
    "    http = urllib3.PoolManager()\n",
    "    page = http.request(\"GET\", \"http://www.espn.com/mens-college-basketball/teams\")\n",
    "    soup = BeautifulSoup(page.data, \"html.parser\")\n",
    "    paragraphs = soup.find_all(\"h5\")\n",
    "    team_ids = {}\n",
    "    for h5 in paragraphs:\n",
    "        try:\n",
    "            team = re.search(r'>[A-Za-z| |\\'|-]+</a>',str(h5)).group(0)[1:-4]\n",
    "            match = re.search(r'/_/id/[0-9]+/',str(h5)).group(0)[6:-1]\n",
    "            team_ids[team] = (match)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    return team_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gather_all_Reg_stats():\n",
    "    team_ids = gather_teamIds()\n",
    "    years = [2002 + i for i in range(16)]\n",
    "    team_games = {}\n",
    "\n",
    "    for year in years:\n",
    "        print(year)\n",
    "        for team in team_ids.values():\n",
    "            games = []\n",
    "            http = urllib3.PoolManager()\n",
    "            page = http.request(\"GET\", \"http://www.espn.com/mens-college-basketball/team/schedule/_/id/{}/year/{}\".format(team,year))\n",
    "            soup = BeautifulSoup(page.data, \"html.parser\")\n",
    "            paragraphs = soup.find_all(\"table\")\n",
    "            for tb in paragraphs:\n",
    "                match = re.findall(r'gameId/[0-9]+\">[0-9]+-[0-9]+[ OT]*<',str(tb))\n",
    "                opponent = re.findall(r'/_/id/[0-9]+/',str(tb))\n",
    "                for game,opp in zip(match,opponent[::2]):\n",
    "                    games.append(tuple([game.split('>')[1][:-1], opp[6:-1]]))\n",
    "            team_games[str(team)+str(year)] = games\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "\n",
    "def game_key(team1,team2):\n",
    "    return team1 + team2\n",
    "\n",
    "def get_over_under(team1, team2):\n",
    "    ou_dict = {'U':1,'O':0}\n",
    "    browser = webdriver.Firefox()\n",
    "    browser.get('http://www.oddsshark.com/ncaab/database')\n",
    "    team = browser.find_element_by_id(\"team-search-h2h\")\n",
    "\n",
    "    team.send_keys(team1)\n",
    "    opponent = browser.find_element_by_id(\"opponent-search-h2h\")\n",
    "\n",
    "    opponent.send_keys(team2)\n",
    "    browser.find_element_by_id(\"games-30-h2h\").click()\n",
    "    Select(browser.find_element_by_id('chalk-select-game-type-h2h')).select_by_value('PST')\n",
    "    browser.find_element_by_id(\"location-any-h2h\").click()\n",
    "    Select(browser.find_element_by_id('chalk-select-odds-h2h')).select_by_value('ANY')\n",
    "    browser.find_element_by_id(\"submit-h2h\").click()\n",
    "    soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    page = soup.find_all(\"table\")\n",
    "    page = str(page[1]).split(\"</td>\")\n",
    "    tables = [page[x:x+10] for x in range(0,len(page)-1,10)]\n",
    "    games = []\n",
    "    for table in tables:\n",
    "        date = table[0][-12:]\n",
    "        if date[0] == '>':\n",
    "            date = date[1:]\n",
    "        if len(table[-1]) > 4:\n",
    "            games.append((team1, team2, date,table[-2][4:],ou_dict[table[-1][-1]]))\n",
    "        \n",
    "    browser.close()\n",
    "    return games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yearRange = [1995,2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tourneyTeamYear = getTourneyTeamYear(yearRange) #dictionary with year as key and value is list of teams in the tourney that year\n",
    "#done for 1995-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allTeamYear = getAllTeamYear(yearRange,tourneyTeamYear) #dictionary -- all teams played by tournament teams by year\n",
    "#done for 1995-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gameYearData = getGameYearData(yearRange,tourneyTeamYear)#dictionary with year as key and value is a list of lists containing [team1,team2,overall score]\n",
    "#example: '2000': [['Duke', 'Lamar', 137], ['Kansas', 'DePaul', 158]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teamYearData = getTeamYearData(yearRange,allTeamYear)#teamYearData --  dictionary with year as key and value is a dictionary with team as key and value in the form of [[team stats],[opponent stats]] \n",
    "#team/oppenent stats: [0G, 1MP, 2FG, 3FGA, 4FG%, 52P, 62PA, 72P%, 83P, 93PA, 103P%, 11FT, 12FTA, 13FT%, 14ORB, 15DRB, 16TRB, 17AST, 18STL, 19BLK, 20TOV, 21PF, 22PTS, 23PTS/G]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tournamentGameData = getTournamentGameData(yearRange)#dictionary with year as key and value is a list of lists containing [team1,team2,overall score] for everygame in the tournament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "d[game_key(\"Colorado State\",\"Colorado\")] = get_over_under(\"Colorado State\",\"Colorado\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testYear = '2015'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notAdded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tourneyTeamYear[testYear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(allTeamYear[testYear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tournamentGameData[testYear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for team, value in teamYearData[testYear].items():\n",
    "    #print(team,value)\n",
    "len(teamYearData[testYear])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for game in gameYearData[testYear]:\n",
    "#    print(game)\n",
    "len(gameYearData[testYear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gather_teamIds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save dicts to file\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_out = open(\"tourneyTeamYear.pickle\",\"wb\")\n",
    "pickle.dump(tourneyTeamYear, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_out = open(\"allTeamYear.pickle\",\"wb\")\n",
    "pickle.dump(allTeamYear, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_out = open(\"gameYearData.pickle\",\"wb\")\n",
    "pickle.dump(gameYearData, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_out = open(\"teamYearData.pickle\",\"wb\")\n",
    "pickle.dump(teamYearData, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_out = open(\"tournamentGameData.pickle\",\"wb\")\n",
    "pickle.dump(tournamentGameData, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"regular_season_games_espn.pkl\",\"wb\") as f:\n",
    "    pickle.dump(team_games,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ohio State', 'UTSA', 'Mar 18, 2011', '140.5', 1)]\n",
      "[('George Mason', 'Villanova', 'Mar 18, 2011', '135.0', 1)]\n",
      "[('West Virginia', 'Clemson', 'Mar 17, 2011', '123.5', 0), ('West Virginia', 'Clemson', 'Mar 29, 2007', '138.0', 0)]\n",
      "[('Kentucky', 'Princeton', 'Mar 17, 2011', '132.5', 1)]\n",
      "[('Xavier', 'Marquette', 'Mar 18, 2011', '141.0', 1)]\n",
      "[('Syracuse', 'Indiana State', 'Mar 18, 2011', '129.0', 0)]\n",
      "[('Washington', 'Georgia', 'Mar 18, 2011', '146.0', 1)]\n",
      "[('Ohio State', 'George Mason', 'Mar 20, 2011', '136.5', 0)]\n",
      "[('Marquette', 'Syracuse', 'Mar 30, 2013', '126.5', 1), ('Marquette', 'Syracuse', 'Mar 20, 2011', '138.0', 1)]\n",
      "[('Washington', 'UNC', 'Mar 21, 2016', '149.5', 0), ('Washington', 'UNC', 'Mar 15, 2016', '167.5', 0), ('Washington', 'UNC', 'Mar 19, 2013', '148.0', 0), ('Washington', 'UNC', 'Mar 27, 2012', '144.5', 1), ('Washington', 'UNC', 'Mar 20, 2012', '153.5', 0), ('Washington', 'UNC', 'Mar 16, 2012', '148.0', 1), ('Washington', 'UNC', 'Mar 13, 2012', '157.0', 1), ('Washington', 'UNC', 'Mar 20, 2011', '159.0', 0), ('Washington', 'UNC', 'Mar 18, 2011', '146.0', 1), ('Washington', 'UNC', 'Mar 25, 2010', '140.5', 1), ('Washington', 'UNC', 'Mar 20, 2010', '151.0', 1), ('Washington', 'UNC', 'Mar 18, 2010', '140.5', 0), ('Washington', 'UNC', 'Mar 21, 2009', '139.5', 0), ('Washington', 'UNC', 'Mar 19, 2009', '148.5', 1), ('Washington', 'UNC', 'Mar 19, 2008', '145.5', 1), ('Washington', 'UNC', 'Mar 24, 2006', '156.0', 0), ('Washington', 'UNC', 'Mar 18, 2006', '143.5', 1), ('Washington', 'UNC', 'Mar 16, 2006', '144.0', 1), ('Washington', 'UNC', 'Mar 24, 2005', '158.5', 0), ('Washington', 'UNC', 'Mar 19, 2005', '155.5', 0), ('Washington', 'UNC', 'Mar 17, 2005', '155.0', 0), ('Washington', 'UNC', 'Mar 19, 2004', '159.0', 0)]\n",
      "[('Ohio State', 'Kentucky', 'Mar 25, 2011', '141.0', 1)]\n",
      "[('Butler', 'Old Dominion', 'Mar 17, 2011', '123.0', 1), ('Butler', 'Old Dominion', 'Mar 15, 2007', '123.5', 1)]\n",
      "[('Kansas State', 'Utah State', 'Mar 17, 2011', '128.5', 0)]\n",
      "[('Wisconsin', 'Belmont', 'Mar 17, 2011', '128.0', 0)]\n",
      "[('BYU', 'Wofford', 'Mar 17, 2011', '148.0', 1)]\n",
      "[('UCLA', 'Michigan State', 'Mar 17, 2011', '130.5', 0)]\n",
      "[('Kansas State', 'Wisconsin', 'Mar 19, 2011', '124.0', 0), ('Kansas State', 'Wisconsin', 'Mar 22, 2008', '130.5', 1)]\n",
      "[('Gonzaga', 'BYU', 'Mar 19, 2011', '149.5', 0)]\n",
      "[('Butler', 'Wisconsin', 'Mar 24, 2011', '124.0', 1)]\n",
      "[('Kansas', 'Boston University', 'Mar 18, 2011', '137.5', 1)]\n",
      "[('Louisville', 'Morehead State', 'Mar 17, 2011', '132.0', 1), ('Louisville', 'Morehead State', 'Mar 20, 2009', '131.0', 1)]\n",
      "[('Purdue', \"St. Peter's\", 'Mar 23, 2017', '155.5', 0), ('Purdue', \"St. Peter's\", 'Mar 18, 2017', '154.5', 0), ('Purdue', \"St. Peter's\", 'Mar 16, 2017', '135.0', 0), ('Purdue', \"St. Peter's\", 'Mar 17, 2016', '127.5', 0), ('Purdue', \"St. Peter's\", 'Mar 19, 2015', '117.0', 0), ('Purdue', \"St. Peter's\", 'Mar 25, 2013', '144.0', 0), ('Purdue', \"St. Peter's\", 'Mar 20, 2013', '116.5', 0), ('Purdue', \"St. Peter's\", 'Mar 18, 2012', '142.0', 1), ('Purdue', \"St. Peter's\", 'Mar 16, 2012', '141.5', 1), ('Purdue', \"St. Peter's\", 'Mar 20, 2011', '133.5', 0), ('Purdue', \"St. Peter's\", 'Mar 18, 2011', '122.5', 1), ('Purdue', \"St. Peter's\", 'Mar 26, 2010', '128.0', 1), ('Purdue', \"St. Peter's\", 'Mar 21, 2010', '127.0', 1), ('Purdue', \"St. Peter's\", 'Mar 19, 2010', '132.0', 0), ('Purdue', \"St. Peter's\", 'Mar 26, 2009', '133.5', 1), ('Purdue', \"St. Peter's\", 'Mar 21, 2009', '139.5', 0), ('Purdue', \"St. Peter's\", 'Mar 19, 2009', '124.5', 1), ('Purdue', \"St. Peter's\", 'Mar 22, 2008', '132.5', 0), ('Purdue', \"St. Peter's\", 'Mar 20, 2008', '145.5', 0), ('Purdue', \"St. Peter's\", 'Mar 18, 2007', '135.0', 0), ('Purdue', \"St. Peter's\", 'Mar 16, 2007', '140.0', 1), ('Purdue', \"St. Peter's\", 'Mar 17, 2004', '127.5', 0), ('Purdue', \"St. Peter's\", 'Mar 23, 2003', '144.5', 1), ('Purdue', \"St. Peter's\", 'Mar 21, 2003', '134.5', 0), ('Purdue', \"St. Peter's\", 'Mar 23, 2001', '146.0', 0), ('Purdue', \"St. Peter's\", 'Mar 20, 2001', '146.0', 1), ('Purdue', \"St. Peter's\", 'Mar 14, 2001', '143.0', 0)]\n",
      "[('Notre Dame', 'Akron', 'Mar 18, 2011', '138.0', 1)]\n",
      "[('Richmond', 'Morehead State', 'Mar 19, 2011', '124.0', 1)]\n",
      "[('VCU', 'Purdue', 'Mar 20, 2011', '133.5', 0)]\n",
      "[('Florida State', 'Notre Dame', 'Mar 20, 2011', '130.5', 1)]\n",
      "[('Kansas', 'Richmond', 'Mar 25, 2011', '135.5', 1)]\n",
      "[('VCU', 'Florida State', 'Mar 25, 2011', '130.5', 0)]\n",
      "[('Kansas', 'VCU', 'Mar 27, 2011', '145.5', 1)]\n",
      "[('Duke', 'Hampton', 'Mar 18, 2011', '135.5', 1)]\n",
      "[('Michigan', 'Tennessee', 'Mar 28, 2014', '136.0', 0), ('Michigan', 'Tennessee', 'Mar 18, 2011', '127.5', 1)]\n",
      "[('Arizona', 'Memphis', 'Mar 18, 2011', '140.0', 0)]\n",
      "[('Texas', 'Oakland', 'Mar 18, 2011', '157.0', 0)]\n",
      "[('Temple', 'Penn State', 'Mar 17, 2011', '118.0', 0), ('Temple', 'Penn State', 'Mar 23, 2001', '139.0', 0)]\n",
      "[('San Diego State', 'Northern Colorado', 'Mar 17, 2011', '130.0', 1)]\n",
      "[('Duke', 'Michigan', 'Mar 20, 2011', '136.0', 0)]\n",
      "[('Temple', 'San Diego State', 'Mar 19, 2011', '125.5', 0)]\n",
      "[('Duke', 'Arizona', 'Mar 24, 2011', '147.5', 0), ('Duke', 'Arizona', 'Apr 2, 2001', '164.0', 1)]\n",
      "[('Arizona', 'UConn', 'Mar 23, 2017', '144.5', 1), ('Arizona', 'UConn', 'Mar 18, 2017', '136.5', 1), ('Arizona', 'UConn', 'Mar 16, 2017', '146.5', 0), ('Arizona', 'UConn', 'Mar 17, 2016', '136.0', 1), ('Arizona', 'UConn', 'Mar 28, 2015', '132.0', 0), ('Arizona', 'UConn', 'Mar 26, 2015', '139.0', 1), ('Arizona', 'UConn', 'Mar 21, 2015', '139.5', 1), ('Arizona', 'UConn', 'Mar 19, 2015', '134.5', 0), ('Arizona', 'UConn', 'Mar 29, 2014', '132.0', 1), ('Arizona', 'UConn', 'Mar 27, 2014', '120.0', 0), ('Arizona', 'UConn', 'Mar 23, 2014', '128.0', 0), ('Arizona', 'UConn', 'Mar 21, 2014', '127.5', 1), ('Arizona', 'UConn', 'Mar 28, 2013', '133.5', 0), ('Arizona', 'UConn', 'Mar 23, 2013', '133.0', 1), ('Arizona', 'UConn', 'Mar 21, 2013', '139.5', 0), ('Arizona', 'UConn', 'Mar 14, 2012', '132.0', 1), ('Arizona', 'UConn', 'Mar 26, 2011', '147.0', 1), ('Arizona', 'UConn', 'Mar 24, 2011', '147.5', 0), ('Arizona', 'UConn', 'Mar 20, 2011', '142.0', 1), ('Arizona', 'UConn', 'Mar 18, 2011', '140.0', 0), ('Arizona', 'UConn', 'Mar 27, 2009', '138.5', 0), ('Arizona', 'UConn', 'Mar 22, 2009', '134.5', 1), ('Arizona', 'UConn', 'Mar 20, 2009', '134.0', 0), ('Arizona', 'UConn', 'Mar 20, 2008', '139.0', 0), ('Arizona', 'UConn', 'Mar 16, 2007', '140.0', 1), ('Arizona', 'UConn', 'Mar 19, 2006', '143.5', 0), ('Arizona', 'UConn', 'Mar 17, 2006', '138.0', 0), ('Arizona', 'UConn', 'Mar 26, 2005', '144.5', 0), ('Arizona', 'UConn', 'Mar 24, 2005', '149.0', 0), ('Arizona', 'UConn', 'Mar 19, 2005', '157.5', 1)]\n"
     ]
    }
   ],
   "source": [
    "with open(\"tournamentGameData.pickle\",'rb') as f:\n",
    "    tournament_data = pickle.load(f)\n",
    "with open(\"teamYearData.pickle\",\"rb\") as f:\n",
    "    team_stats = pickle.load(f)\n",
    "year = \"2011\"\n",
    "stats = team_stats[year]\n",
    "all_over_under = []\n",
    "for game in tournament_data[year]:\n",
    "    try:\n",
    "        ou = get_over_under(game[0],game[1])\n",
    "        print(ou)\n",
    "        all_over_under.append(ou)\n",
    "    except:\n",
    "        pass\n",
    "    team = stats[game[0]][0]\n",
    "    opponent = stats[game[0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"all_over_under_2011.pkl\",'wb') as f:\n",
    "    pickle.dump(all_over_under, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(all_over_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years = [\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\"]\n",
    "all_over_under = []\n",
    "valid_games = []\n",
    "for year in years:\n",
    "    with open(\"all_over_under_{}.pkl\".format(year),'rb') as f:\n",
    "        all_over_under += pickle.load(f)\n",
    "all_over_under = all_over_under[1:]\n",
    "for team in all_over_under:\n",
    "    if len(item) > 1:\n",
    "        tournament_game = []\n",
    "        for game in team:\n",
    "            if game[2][-4:] in years:\n",
    "                tournament_game.append(game)\n",
    "        if len(tournament_game) < 2:\n",
    "            valid_games.append(tournament_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"valid_classification_games.pkl\",'wb') as f:\n",
    "    pickle.dump(valid_games,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how to load\n",
    "#pickle_in = open(\"dict.pickle\",\"rb\")\n",
    "#example_dict = pickle.load(pickle_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
